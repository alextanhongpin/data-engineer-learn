# data-engineer-learn

Stuff to learn as a data engineer

## What are data engineers?

https://www.cio.com/article/3292983/what-is-a-data-engineer.html

> Data engineers are vital members of any enterprise data analytics team, responsible for managing, optimising, overseeing and monitoring data retrieval, storage and distribution throughout the organisation.

## Data engineer role

- __Generalist__: typically found in small teams or in small companies. Generalists are often responsible for every step of the data process, from managing data to analysing it.
- __Pipeline-centric__: Often found in midsize companies, pipeline-centric data engineers work alongside data scientists to help make use of the data they collect. Pipeline-centric data engineers need “in-depth knowledge of distributed systems and computer science”
- __Database-centric__: In larger organisations, while managing the flow of data is a full-time job, data engineers focus on analytics databases. Database-centric data engineers work with data warehouse across multiple databases and are responsible for developing table schemas.

## Data engineers responsibility

- Develop, construct, test and mantain architecture (how to develop one? Are there any basic design?)
- Align architecture with business requirements (what does this mean? Say, if we need to mine twitter, then the architecture is more on firing rest api to get the Twitter data. If we need to get data from the database, then we can use mysql binlog or ETL)
- Data acquisition (from different sources, CSV, SQL, rest api). Take a look at Presto?
- Develop data set processes? (Could be in the enricher pipeline)
- Use programming languages and tools (what are languages used? Scala and python. What are the tools used?)
- Identify ways to improve data reliability, efficiency and quality
- Conduct research for industry and business questions
- Use large data sets to question business issues (?aggregation of data provides summary)
- Deploy sophisticated analytics programs, machine learning and statistical methods). 
- Prepare data for predictive and prescriptive modelling (how? Feature selection? Remove null/fill up null values)
- Find hidden patterns using data (clustering?)
- Use data to discover tasks that can be automated
- Deliver updates to stakeholder based on analytics

## Data engineer skills

- Scala
- Apache spark
- Data warehouse
- Java
- Data modeling
- Apache Hadoop
- Linux
- Amazon web services 
- ETL 
- Big data analytics
- Software development


## Questions

- [What is the difference between data engineer and data scientist?](#difference)
- How does a typical data pipeline looks like
- What steps are available?
- How to know if a job is completed?
- How to handle errors?
- How to handle versioning of data?
- How to improve performance (using binary data such as protobuff/thrift, or maybe parquet)
- What is Presto, and other alternatives?
- High availability
- What are all the machine learning algorithms that can be applied to analyse a dataset? 
- data preparation steps
- How to build ETL (scalable, performant) pipelines?
- How to build connectors (http, rest, soap)
- What kind of sources and sinks are available?
- What kind of monitoring tools to look at?
- What is Inmon and Kimball approach for data warehousing?
- Star vs snowflake schemas
- What are the different types of data sources
    - server logs
        - server access logs. These contains one line per request made to the server from the app. Nginx access logs can be used.
        - server error logs. These contains all the server-side errors generated by your app.
    - App analytics logs
        - app events logs. These contains information about what actions users took in the app, e.g. when user update payment info, user click purchase button
        - app error logs: These contain information about errors in the app.
    - Database. SQL, no SQL. the single source of truth of the final state of the data.
    - Text file. CSV, Word, excel etc.
- How to perform autoscaling? There are times when there are spike requests. This requires the system to be scaled up when that time arrives. Some services might have less usage at midnight, and we need to find ways to scale down the service.

## Phases in data pipeline
- ingestion: gathering the needed data
- processing: processing the data to get the result you want
- storage: this involves storing the end result for fast retrieval
- access: you will need to enable a tool or user to access the end results of the pipeline

## <a id='difference'> Difference between data scientist and data engineers</a>

> Data engineers are the plumbers building a data pipeline, while data scientists are the painters and storytellers, giving meaning to an otherwise static entity.

- Data engineers are more focused on building infrastructure and architecture of data generation. 
- Data scientist are focused rather on advanced mathematics and statistical analytics on that generated data.
- Data engineers and data scientist complements one another

References:
- https://blog.panoply.io/what-is-the-difference-between-a-data-engineer-and-a-data-scientist

## Key skills for data engineers

- In-depth knowledge of SQL and other databases solution
- Data warehouse architecture and ETL tools, e.g. Redshift, Panoply. 


Data modelling Kimball

## References

https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/
https://www.kdnuggets.com/2019/01/role-data-engineer-changing.html
https://www.dataquest.io/blog/what-is-a-data-engineer/
https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century?source=post_page---------------------------
https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007?source=post_page---------------------------
https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying
https://medium.com/@samson_hu/building-analytics-at-500px-92e9a7005c83
https://www.alooma.com/blog/what-is-a-data-pipeline
